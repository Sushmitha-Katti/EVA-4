{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S12_V1(Template for Tiny_ImageNet).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMrhy3bycKicbS/prTcYKYo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sushmitha-Katti/EVA-4/blob/master/Session12/S12_V1(Template_for_Tiny_ImageNet).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDCQhZeHyqfb",
        "colab_type": "text"
      },
      "source": [
        "# **Object classification on Tiny Imagenet Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAsvhm1SyGGw",
        "colab_type": "text"
      },
      "source": [
        "## **Only problem is to handle black and white data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2sF8aSvvT9g",
        "colab_type": "code",
        "outputId": "765f6557-a911-4c42-f596-d8cb911f22f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount( '/content/drive', force_remount=True )"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4iRwPSptj8a",
        "colab_type": "text"
      },
      "source": [
        "## **Download the Tiny Imagenet Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESDoqGr2B7qr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bda822a0-dbe2-4963-f249-f6fbda223bdb"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "from io import StringIO,BytesIO\n",
        "def download_images(url):\n",
        "\n",
        "    if (os.path.isdir(\"tiny-imagenet-200.zip\")):\n",
        "        print ('Images already downloaded...')\n",
        "        return\n",
        "    r = requests.get(url, stream=True)\n",
        "    print ('Downloading ' + url )\n",
        "    zip_ref = zipfile.ZipFile(BytesIO(r.content))\n",
        "    zip_ref.extractall('./')\n",
        "    zip_ref.close()\n",
        "download_images(\"http://cs231n.stanford.edu/tiny-imagenet-200.zip\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://cs231n.stanford.edu/tiny-imagenet-200.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsHFU2VcMWcZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ff221b3-556b-4bbd-c1ae-d3a0859255b5"
      },
      "source": [
        "!ls tiny-imagenet-200"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test  train  val  wnids.txt  words.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thCRkCwrtyoW",
        "colab_type": "text"
      },
      "source": [
        "## **To know about python file operation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU89Vg7mNPti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca5b1c6c-2d05-4db7-b652-7e51b0bc14cb"
      },
      "source": [
        "f = open(\"tiny-imagenet-200/wnids.txt\", \"r\")\n",
        "\n",
        "for line in f:\n",
        "  print(line)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n02124075\n",
            "\n",
            "n04067472\n",
            "\n",
            "n04540053\n",
            "\n",
            "n04099969\n",
            "\n",
            "n07749582\n",
            "\n",
            "n01641577\n",
            "\n",
            "n02802426\n",
            "\n",
            "n09246464\n",
            "\n",
            "n07920052\n",
            "\n",
            "n03970156\n",
            "\n",
            "n03891332\n",
            "\n",
            "n02106662\n",
            "\n",
            "n03201208\n",
            "\n",
            "n02279972\n",
            "\n",
            "n02132136\n",
            "\n",
            "n04146614\n",
            "\n",
            "n07873807\n",
            "\n",
            "n02364673\n",
            "\n",
            "n04507155\n",
            "\n",
            "n03854065\n",
            "\n",
            "n03838899\n",
            "\n",
            "n03733131\n",
            "\n",
            "n01443537\n",
            "\n",
            "n07875152\n",
            "\n",
            "n03544143\n",
            "\n",
            "n09428293\n",
            "\n",
            "n03085013\n",
            "\n",
            "n02437312\n",
            "\n",
            "n07614500\n",
            "\n",
            "n03804744\n",
            "\n",
            "n04265275\n",
            "\n",
            "n02963159\n",
            "\n",
            "n02486410\n",
            "\n",
            "n01944390\n",
            "\n",
            "n09256479\n",
            "\n",
            "n02058221\n",
            "\n",
            "n04275548\n",
            "\n",
            "n02321529\n",
            "\n",
            "n02769748\n",
            "\n",
            "n02099712\n",
            "\n",
            "n07695742\n",
            "\n",
            "n02056570\n",
            "\n",
            "n02281406\n",
            "\n",
            "n01774750\n",
            "\n",
            "n02509815\n",
            "\n",
            "n03983396\n",
            "\n",
            "n07753592\n",
            "\n",
            "n04254777\n",
            "\n",
            "n02233338\n",
            "\n",
            "n04008634\n",
            "\n",
            "n02823428\n",
            "\n",
            "n02236044\n",
            "\n",
            "n03393912\n",
            "\n",
            "n07583066\n",
            "\n",
            "n04074963\n",
            "\n",
            "n01629819\n",
            "\n",
            "n09332890\n",
            "\n",
            "n02481823\n",
            "\n",
            "n03902125\n",
            "\n",
            "n03404251\n",
            "\n",
            "n09193705\n",
            "\n",
            "n03637318\n",
            "\n",
            "n04456115\n",
            "\n",
            "n02666196\n",
            "\n",
            "n03796401\n",
            "\n",
            "n02795169\n",
            "\n",
            "n02123045\n",
            "\n",
            "n01855672\n",
            "\n",
            "n01882714\n",
            "\n",
            "n02917067\n",
            "\n",
            "n02988304\n",
            "\n",
            "n04398044\n",
            "\n",
            "n02843684\n",
            "\n",
            "n02423022\n",
            "\n",
            "n02669723\n",
            "\n",
            "n04465501\n",
            "\n",
            "n02165456\n",
            "\n",
            "n03770439\n",
            "\n",
            "n02099601\n",
            "\n",
            "n04486054\n",
            "\n",
            "n02950826\n",
            "\n",
            "n03814639\n",
            "\n",
            "n04259630\n",
            "\n",
            "n03424325\n",
            "\n",
            "n02948072\n",
            "\n",
            "n03179701\n",
            "\n",
            "n03400231\n",
            "\n",
            "n02206856\n",
            "\n",
            "n03160309\n",
            "\n",
            "n01984695\n",
            "\n",
            "n03977966\n",
            "\n",
            "n03584254\n",
            "\n",
            "n04023962\n",
            "\n",
            "n02814860\n",
            "\n",
            "n01910747\n",
            "\n",
            "n04596742\n",
            "\n",
            "n03992509\n",
            "\n",
            "n04133789\n",
            "\n",
            "n03937543\n",
            "\n",
            "n02927161\n",
            "\n",
            "n01945685\n",
            "\n",
            "n02395406\n",
            "\n",
            "n02125311\n",
            "\n",
            "n03126707\n",
            "\n",
            "n04532106\n",
            "\n",
            "n02268443\n",
            "\n",
            "n02977058\n",
            "\n",
            "n07734744\n",
            "\n",
            "n03599486\n",
            "\n",
            "n04562935\n",
            "\n",
            "n03014705\n",
            "\n",
            "n04251144\n",
            "\n",
            "n04356056\n",
            "\n",
            "n02190166\n",
            "\n",
            "n03670208\n",
            "\n",
            "n02002724\n",
            "\n",
            "n02074367\n",
            "\n",
            "n04285008\n",
            "\n",
            "n04560804\n",
            "\n",
            "n04366367\n",
            "\n",
            "n02403003\n",
            "\n",
            "n07615774\n",
            "\n",
            "n04501370\n",
            "\n",
            "n03026506\n",
            "\n",
            "n02906734\n",
            "\n",
            "n01770393\n",
            "\n",
            "n04597913\n",
            "\n",
            "n03930313\n",
            "\n",
            "n04118538\n",
            "\n",
            "n04179913\n",
            "\n",
            "n04311004\n",
            "\n",
            "n02123394\n",
            "\n",
            "n04070727\n",
            "\n",
            "n02793495\n",
            "\n",
            "n02730930\n",
            "\n",
            "n02094433\n",
            "\n",
            "n04371430\n",
            "\n",
            "n04328186\n",
            "\n",
            "n03649909\n",
            "\n",
            "n04417672\n",
            "\n",
            "n03388043\n",
            "\n",
            "n01774384\n",
            "\n",
            "n02837789\n",
            "\n",
            "n07579787\n",
            "\n",
            "n04399382\n",
            "\n",
            "n02791270\n",
            "\n",
            "n03089624\n",
            "\n",
            "n02814533\n",
            "\n",
            "n04149813\n",
            "\n",
            "n07747607\n",
            "\n",
            "n03355925\n",
            "\n",
            "n01983481\n",
            "\n",
            "n04487081\n",
            "\n",
            "n03250847\n",
            "\n",
            "n03255030\n",
            "\n",
            "n02892201\n",
            "\n",
            "n02883205\n",
            "\n",
            "n03100240\n",
            "\n",
            "n02415577\n",
            "\n",
            "n02480495\n",
            "\n",
            "n01698640\n",
            "\n",
            "n01784675\n",
            "\n",
            "n04376876\n",
            "\n",
            "n03444034\n",
            "\n",
            "n01917289\n",
            "\n",
            "n01950731\n",
            "\n",
            "n03042490\n",
            "\n",
            "n07711569\n",
            "\n",
            "n04532670\n",
            "\n",
            "n03763968\n",
            "\n",
            "n07768694\n",
            "\n",
            "n02999410\n",
            "\n",
            "n03617480\n",
            "\n",
            "n06596364\n",
            "\n",
            "n01768244\n",
            "\n",
            "n02410509\n",
            "\n",
            "n03976657\n",
            "\n",
            "n01742172\n",
            "\n",
            "n03980874\n",
            "\n",
            "n02808440\n",
            "\n",
            "n02226429\n",
            "\n",
            "n02231487\n",
            "\n",
            "n02085620\n",
            "\n",
            "n01644900\n",
            "\n",
            "n02129165\n",
            "\n",
            "n02699494\n",
            "\n",
            "n03837869\n",
            "\n",
            "n02815834\n",
            "\n",
            "n07720875\n",
            "\n",
            "n02788148\n",
            "\n",
            "n02909870\n",
            "\n",
            "n03706229\n",
            "\n",
            "n07871810\n",
            "\n",
            "n03447447\n",
            "\n",
            "n02113799\n",
            "\n",
            "n12267677\n",
            "\n",
            "n03662601\n",
            "\n",
            "n02841315\n",
            "\n",
            "n07715103\n",
            "\n",
            "n02504458\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4luUchuuK8j",
        "colab_type": "text"
      },
      "source": [
        "## **To know about PIL operation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPlpaEcIMaRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !ls tiny-imagenet-200/train/n02504458/images\n",
        "\n",
        "from PIL import Image\n",
        "a = Image.open(\"tiny-imagenet-200/train/n02504458/images/n02504458_181.JPEG\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBvJu1fbuVHL",
        "colab_type": "text"
      },
      "source": [
        "## **Converstion from image to numpy array and vise versa** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2nsV3_oMx9d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "outputId": "82eaaf77-5eb1-4b2a-9a34-79ce4eb98956"
      },
      "source": [
        "import numpy as np\n",
        "npimg = np.asarray(a)\n",
        "print(npimg.shape)\n",
        "print(npimg)\n",
        "\n",
        "#convert numpy image back to PIL image and display it\n",
        "npimg = Image.fromarray(npimg )\n",
        "display(npimg)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 64, 3)\n",
            "[[[218 218 220]\n",
            "  [218 218 220]\n",
            "  [218 218 220]\n",
            "  ...\n",
            "  [220 221 223]\n",
            "  [220 221 223]\n",
            "  [220 221 223]]\n",
            "\n",
            " [[218 218 220]\n",
            "  [218 218 220]\n",
            "  [218 218 220]\n",
            "  ...\n",
            "  [220 221 223]\n",
            "  [220 221 223]\n",
            "  [220 221 223]]\n",
            "\n",
            " [[218 218 220]\n",
            "  [218 218 220]\n",
            "  [218 218 220]\n",
            "  ...\n",
            "  [220 221 223]\n",
            "  [220 221 223]\n",
            "  [220 221 223]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 91  89  51]\n",
            "  [ 73  71  33]\n",
            "  [ 76  74  36]\n",
            "  ...\n",
            "  [ 96  92  54]\n",
            "  [ 95  91  53]\n",
            "  [ 99  95  57]]\n",
            "\n",
            " [[ 98  95  60]\n",
            "  [ 96  93  58]\n",
            "  [112 109  74]\n",
            "  ...\n",
            "  [103  99  61]\n",
            "  [105 101  63]\n",
            "  [105 101  63]]\n",
            "\n",
            " [[104 101  68]\n",
            "  [ 87  84  51]\n",
            "  [ 95  92  59]\n",
            "  ...\n",
            "  [ 92  90  52]\n",
            "  [ 99  97  59]\n",
            "  [ 98  96  58]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F39A133BEF0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi_Q6HbNuott",
        "colab_type": "text"
      },
      "source": [
        "## **This is how CIFAR10 dataset is implemented**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z8sqRyco9_1H",
        "colab": {}
      },
      "source": [
        "\n",
        "from __future__ import print_function\n",
        "from PIL import Image\n",
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "if sys.version_info[0] == 2:\n",
        "    import cPickle as pickle\n",
        "else:\n",
        "    import pickle\n",
        "\n",
        "from .vision import VisionDataset\n",
        "from .utils import check_integrity, download_and_extract_archive\n",
        "\n",
        "\n",
        "class CIFAR10(VisionDataset):\n",
        "    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
        "\n",
        "    Args:\n",
        "        root (string): Root directory of dataset where directory\n",
        "            ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n",
        "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
        "            creates from test set.\n",
        "        transform (callable, optional): A function/transform that takes in an PIL image\n",
        "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
        "        target_transform (callable, optional): A function/transform that takes in the\n",
        "            target and transforms it.\n",
        "        download (bool, optional): If true, downloads the dataset from the internet and\n",
        "            puts it in root directory. If dataset is already downloaded, it is not\n",
        "            downloaded again.\n",
        "\n",
        "    \"\"\"\n",
        "    base_folder = 'tiny-imagenet-200'\n",
        "    url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
        "    filename = \"tiny-10-python.zip\"\n",
        "    tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
        "    train_list = [\n",
        "        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
        "        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
        "        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
        "        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
        "        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
        "    ]\n",
        "\n",
        "    test_list = [\n",
        "        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
        "    ]\n",
        "    meta = {\n",
        "        'filename': 'batches.meta',\n",
        "        'key': 'label_names',\n",
        "        'md5': '5ff9c542aee3614f3951f8cda6e48888',\n",
        "    }\n",
        "\n",
        "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
        "                 download=False):\n",
        "\n",
        "        super(CIFAR10, self).__init__(root, transform=transform,\n",
        "                                      target_transform=target_transform)\n",
        "\n",
        "        self.train = train  # training set or test set\n",
        "\n",
        "        if download:\n",
        "            self.download()\n",
        "\n",
        "        if not self._check_integrity():\n",
        "            raise RuntimeError('Dataset not found or corrupted.' +\n",
        "                               ' You can use download=True to download it')\n",
        "\n",
        "        if self.train:\n",
        "            downloaded_list = self.train_list\n",
        "        else:\n",
        "            downloaded_list = self.test_list\n",
        "\n",
        "        self.data = []\n",
        "        self.targets = []\n",
        "\n",
        "        # now load the picked numpy arrays\n",
        "        for file_name, checksum in downloaded_list:\n",
        "            file_path = os.path.join(self.root, self.base_folder, file_name)\n",
        "            with open(file_path, 'rb') as f:\n",
        "                if sys.version_info[0] == 2:\n",
        "                    entry = pickle.load(f)\n",
        "                else:\n",
        "                    entry = pickle.load(f, encoding='latin1')\n",
        "                self.data.append(entry['data'])\n",
        "                if 'labels' in entry:\n",
        "                    self.targets.extend(entry['labels'])\n",
        "                else:\n",
        "                    self.targets.extend(entry['fine_labels'])\n",
        "\n",
        "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
        "        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
        "\n",
        "        self._load_meta()\n",
        "\n",
        "    def _load_meta(self):\n",
        "        path = os.path.join(self.root, self.base_folder, self.meta['filename'])\n",
        "        if not check_integrity(path, self.meta['md5']):\n",
        "            raise RuntimeError('Dataset metadata file not found or corrupted.' +\n",
        "                               ' You can use download=True to download it')\n",
        "        with open(path, 'rb') as infile:\n",
        "            if sys.version_info[0] == 2:\n",
        "                data = pickle.load(infile)\n",
        "            else:\n",
        "                data = pickle.load(infile, encoding='latin1')\n",
        "            self.classes = data[self.meta['key']]\n",
        "        self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n",
        "\n",
        "[docs]    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _check_integrity(self):\n",
        "        root = self.root\n",
        "        for fentry in (self.train_list + self.test_list):\n",
        "            filename, md5 = fentry[0], fentry[1]\n",
        "            fpath = os.path.join(root, self.base_folder, filename)\n",
        "            if not check_integrity(fpath, md5):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def download(self):\n",
        "        if self._check_integrity():\n",
        "            print('Files already downloaded and verified')\n",
        "            return\n",
        "        download_and_extract_archive(self.url, self.root, filename=self.filename, md5=self.tgz_md5)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return \"Split: {}\".format(\"Train\" if self.train is True else \"Test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ulf7V0scuzG2",
        "colab_type": "text"
      },
      "source": [
        "## **Simple implementation of custom dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg2yCtB202fU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "8c540e77-a801-4b83-bc5f-95527d6defe8"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class NumbersDataset(Dataset):\n",
        "    def __init__(self, low, high):\n",
        "        self.samples = list(range(low, high))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    dataset = NumbersDataset(2821, 8295)\n",
        "    print(len(dataset))\n",
        "    print(dataset[100])\n",
        "    print(dataset[122:361])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5474\n",
            "2921\n",
            "[2943, 2944, 2945, 2946, 2947, 2948, 2949, 2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2958, 2959, 2960, 2961, 2962, 2963, 2964, 2965, 2966, 2967, 2968, 2969, 2970, 2971, 2972, 2973, 2974, 2975, 2976, 2977, 2978, 2979, 2980, 2981, 2982, 2983, 2984, 2985, 2986, 2987, 2988, 2989, 2990, 2991, 2992, 2993, 2994, 2995, 2996, 2997, 2998, 2999, 3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3045, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087, 3088, 3089, 3090, 3091, 3092, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100, 3101, 3102, 3103, 3104, 3105, 3106, 3107, 3108, 3109, 3110, 3111, 3112, 3113, 3114, 3115, 3116, 3117, 3118, 3119, 3120, 3121, 3122, 3123, 3124, 3125, 3126, 3127, 3128, 3129, 3130, 3131, 3132, 3133, 3134, 3135, 3136, 3137, 3138, 3139, 3140, 3141, 3142, 3143, 3144, 3145, 3146, 3147, 3148, 3149, 3150, 3151, 3152, 3153, 3154, 3155, 3156, 3157, 3158, 3159, 3160, 3161, 3162, 3163, 3164, 3165, 3166, 3167, 3168, 3169, 3170, 3171, 3172, 3173, 3174, 3175, 3176, 3177, 3178, 3179, 3180, 3181]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzeOldH1vobb",
        "colab_type": "text"
      },
      "source": [
        "## **Listing all Classess to lists**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS63UrC9vm94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"tiny-imagenet-200/wnids.txt\", \"r\")\n",
        "classes = []\n",
        "for line in f:\n",
        "  classes.append(line.strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZx7kIt6u8Dn",
        "colab_type": "text"
      },
      "source": [
        "## **Implementation of Tiny-Imagenet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDLiR-DN03ai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "\n",
        "class TinyImageNet(Dataset):\n",
        "    def __init__(self,url,classes):\n",
        "        self.data = []\n",
        "        self.target = []\n",
        "        self.classes = classes\n",
        "        wnids = open(f\"{url}/wnids.txt\", \"r\")\n",
        "        \n",
        "        for wclass in wnids:\n",
        "          wclass = wclass.strip()\n",
        "          for i in os.listdir(url+'/train/'+wclass+'/images/'):\n",
        "            a = Image.open(url+\"/train/\"+wclass+\"/images/\"+i)\n",
        "            npimg = np.asarray(a)\n",
        "            \n",
        "            if(len(npimg.shape) ==3):\n",
        "             \n",
        "             \n",
        "              self.data.append(npimg)  \n",
        "              self.target.append(self.classes.index(wclass))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data[idx]\n",
        "        target = self.target[idx]\n",
        "        img = data\n",
        "        self.transform =  transforms.Compose(\n",
        "            [   \n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                \n",
        "                \n",
        "            ])\n",
        "        \n",
        "        img = self.transform(img)\n",
        "\n",
        "     \n",
        "\n",
        "        \n",
        "        return img,target\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dataset = TinyImageNet(\"tiny-imagenet-200\",classes)\n",
        "    \n",
        "  \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK1UksjRvHKH",
        "colab_type": "text"
      },
      "source": [
        "## **Train Test Split(70:30)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSTgUannosNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(len(dataloader))\n",
        "# print(len(dataset))\n",
        "train_len = len(dataset)*70//100\n",
        "test_len = len(dataset) - train_len\n",
        "\n",
        "import torch\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [train_len, test_len])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2ZEDSUsvctr",
        "colab_type": "text"
      },
      "source": [
        "## **DataLoader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivDXlf0nqkaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "SEED = 1\n",
        "\n",
        "\t# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "\t# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "\t\t\ttorch.cuda.manual_seed(SEED)\n",
        "trainloader = DataLoader(train_set, batch_size=512, shuffle=True, num_workers=4,pin_memory=True)\n",
        "testloader = DataLoader(val_set, batch_size=512, shuffle=True, num_workers=4,pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puVS_GpUAmqz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b13b005-5bd3-472d-8bc2-19cfec1cb0c1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1CVgU5drc_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import sys\n",
        "folder = '/content/gdrive/My Drive/API'\n",
        "sys.path.append(folder)\n",
        "folder = \"/content/gdrive/My Drive/API/Models\"\n",
        "sys.path.append(folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XDU27uFv1sk",
        "colab_type": "text"
      },
      "source": [
        "## **Importing Required files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yHSlRANA9aW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import train_test_loader\n",
        "import show_images\n",
        "# from ResnetModel import ResNet18\n",
        "import train_test\n",
        "import evaluate\n",
        "from Albumentationtransform import AlbumentationTransforms\n",
        "from GradCam import GradCAM,visualize_cam\n",
        "from LR_Range_Test import LR_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bidyNeFy0mK1",
        "colab_type": "text"
      },
      "source": [
        "## **Used Torchvisions resnet model, but not pre trained. Print the summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxcMgICoIpHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "699b9610-7b73-4104-d2fc-7ecf91b245fe"
      },
      "source": [
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=False)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    # Replace the last fully-connected layer\n",
        "    # Parameters of newly constructed modules have requires_grad=True by default\n",
        "model.fc = nn.Linear(512, 200) # assuming that the fc7 layer has 512 neurons, otherwise change it \n",
        "summary(model, input_size=(3, 64, 64))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
            "            Conv2d-5           [-1, 64, 16, 16]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 16, 16]             128\n",
            "              ReLU-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 64, 16, 16]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
            "             ReLU-10           [-1, 64, 16, 16]               0\n",
            "       BasicBlock-11           [-1, 64, 16, 16]               0\n",
            "           Conv2d-12           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
            "             ReLU-14           [-1, 64, 16, 16]               0\n",
            "           Conv2d-15           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
            "             ReLU-17           [-1, 64, 16, 16]               0\n",
            "       BasicBlock-18           [-1, 64, 16, 16]               0\n",
            "           Conv2d-19            [-1, 128, 8, 8]          73,728\n",
            "      BatchNorm2d-20            [-1, 128, 8, 8]             256\n",
            "             ReLU-21            [-1, 128, 8, 8]               0\n",
            "           Conv2d-22            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-23            [-1, 128, 8, 8]             256\n",
            "           Conv2d-24            [-1, 128, 8, 8]           8,192\n",
            "      BatchNorm2d-25            [-1, 128, 8, 8]             256\n",
            "             ReLU-26            [-1, 128, 8, 8]               0\n",
            "       BasicBlock-27            [-1, 128, 8, 8]               0\n",
            "           Conv2d-28            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-29            [-1, 128, 8, 8]             256\n",
            "             ReLU-30            [-1, 128, 8, 8]               0\n",
            "           Conv2d-31            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-32            [-1, 128, 8, 8]             256\n",
            "             ReLU-33            [-1, 128, 8, 8]               0\n",
            "       BasicBlock-34            [-1, 128, 8, 8]               0\n",
            "           Conv2d-35            [-1, 256, 4, 4]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 4, 4]             512\n",
            "             ReLU-37            [-1, 256, 4, 4]               0\n",
            "           Conv2d-38            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 4, 4]             512\n",
            "           Conv2d-40            [-1, 256, 4, 4]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 4, 4]             512\n",
            "             ReLU-42            [-1, 256, 4, 4]               0\n",
            "       BasicBlock-43            [-1, 256, 4, 4]               0\n",
            "           Conv2d-44            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 4, 4]             512\n",
            "             ReLU-46            [-1, 256, 4, 4]               0\n",
            "           Conv2d-47            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 4, 4]             512\n",
            "             ReLU-49            [-1, 256, 4, 4]               0\n",
            "       BasicBlock-50            [-1, 256, 4, 4]               0\n",
            "           Conv2d-51            [-1, 512, 2, 2]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-53            [-1, 512, 2, 2]               0\n",
            "           Conv2d-54            [-1, 512, 2, 2]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 2, 2]           1,024\n",
            "           Conv2d-56            [-1, 512, 2, 2]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-58            [-1, 512, 2, 2]               0\n",
            "       BasicBlock-59            [-1, 512, 2, 2]               0\n",
            "           Conv2d-60            [-1, 512, 2, 2]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-62            [-1, 512, 2, 2]               0\n",
            "           Conv2d-63            [-1, 512, 2, 2]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-65            [-1, 512, 2, 2]               0\n",
            "       BasicBlock-66            [-1, 512, 2, 2]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                  [-1, 200]         102,600\n",
            "================================================================\n",
            "Total params: 11,279,112\n",
            "Trainable params: 102,600\n",
            "Non-trainable params: 11,176,512\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 5.13\n",
            "Params size (MB): 43.03\n",
            "Estimated Total Size (MB): 48.20\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2756qiux_fDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prWMRFks05H2",
        "colab_type": "text"
      },
      "source": [
        "## **Initialise Optimiser,Scheduler, Criterion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr_OTR8erktV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01,momentum=0.9,weight_decay=0.005 ) \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = OneCycleLR(optimizer, max_lr = 1, total_steps=None, epochs=10, steps_per_epoch=len(trainloader), pct_start=0.5, anneal_strategy='linear', cycle_momentum=False, base_momentum=0.85, max_momentum=0.95, div_factor=10.0,final_div_factor =1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qumgWijf1Fsi",
        "colab_type": "text"
      },
      "source": [
        "## **Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LGzV7sWtGo5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "dd8f3e02-9f62-4687-b4c2-39bc6592cda0"
      },
      "source": [
        "\n",
        "train_test.train_model(model,device,trainloader,testloader,optimizer,criterion,10,scheduler,batch_scheduler=True,best_acc = 0,path = \"/content/gdrive/My Drive/API/tinymodel.pt\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/135 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 1 LR: 0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=6.116085052490234 Batch_id=134 Accuracy=1.52: 100%|| 135/135 [09:29<00:00,  4.22s/it]\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0123, Accuracy: 220/29454 (0.75%)\n",
            "\n",
            "accuracy increased, Saving model....\n",
            "EPOCH: 2 LR: 0.28026706231454007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=79.4408950805664 Batch_id=134 Accuracy=1.43: 100%|| 135/135 [09:34<00:00,  4.25s/it]\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1525, Accuracy: 234/29454 (0.79%)\n",
            "\n",
            "accuracy increased, Saving model....\n",
            "EPOCH: 3 LR: 0.46053412462908017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=156.1199951171875 Batch_id=134 Accuracy=0.88: 100%|| 135/135 [09:29<00:00,  4.22s/it]\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.3345, Accuracy: 199/29454 (0.68%)\n",
            "\n",
            "EPOCH: 4 LR: 0.6408011869436202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=234.8466033935547 Batch_id=134 Accuracy=0.75: 100%|| 135/135 [09:36<00:00,  4.27s/it]\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbM9eDHzTOsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}